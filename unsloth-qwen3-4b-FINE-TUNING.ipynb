{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# üñçÔ∏è Drawing with LLMs: Fine-Tuning Qwen3-4B using Unsloth\n",
    "\n",
    "Welcome to this notebook for the [Drawing with LLMs](https://www.kaggle.com/competitions/drawing-with-llms) competition! Here we aim to train a large language model capable of producing **SVG code** from natural language prompts. This notebook demonstrates how to **fine-tune Qwen3-4B model** using the [Unsloth](https://github.com/unslothai/unsloth) library!\n",
    "\n",
    "The primary objective is to teach the model to generate **high-quality SVG image code** that matches a given textual description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:50:40.268997Z",
     "iopub.status.busy": "2025-05-19T04:50:40.268430Z",
     "iopub.status.idle": "2025-05-19T04:53:44.195433Z",
     "shell.execute_reply": "2025-05-19T04:53:44.194416Z",
     "shell.execute_reply.started": "2025-05-19T04:50:40.268976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pip3-autoremove\n",
    "# !pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model using Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:53:44.197128Z",
     "iopub.status.busy": "2025-05-19T04:53:44.196838Z",
     "iopub.status.idle": "2025-05-19T04:55:59.071164Z",
     "shell.execute_reply": "2025-05-19T04:55:59.070559Z",
     "shell.execute_reply.started": "2025-05-19T04:53:44.197085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 04:54:00.211573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747630440.651742      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747630440.779030      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.5.6: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d73f02be894d9abdebcb58194054f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "cuda:0\n",
      "<class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'>\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "######---Parameters to change---#######\n",
    "dtype = ( None )\n",
    "load_in_4bit = False\n",
    "load_in_8bit = False\n",
    "max_seq_length = 2048\n",
    "Rank=128\n",
    "max_iter_steps=300\n",
    "###--------------------------------###\n",
    "model_name = kagglehub.model_download(\"qwen-lm/qwen-3/transformers/4b\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    load_in_8bit=load_in_8bit\n",
    ")\n",
    "\n",
    "print(model.dtype)       # torch.float16\n",
    "print(model.device)      # cuda:0\n",
    "\n",
    "print(type(model))       # <class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LoRA Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:55:59.120328Z",
     "iopub.status.busy": "2025-05-19T04:55:59.120020Z",
     "iopub.status.idle": "2025-05-19T04:56:07.353522Z",
     "shell.execute_reply": "2025-05-19T04:56:07.352880Z",
     "shell.execute_reply.started": "2025-05-19T04:55:59.120306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.5.6 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = Rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 123,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data from the link [svg-generation-sample-training-data](https://www.kaggle.com/datasets/vinothkumarsekar89/svg-generation-sample-training-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:56:07.354744Z",
     "iopub.status.busy": "2025-05-19T04:56:07.354543Z",
     "iopub.status.idle": "2025-05-19T04:56:07.583555Z",
     "shell.execute_reply": "2025-05-19T04:56:07.582779Z",
     "shell.execute_reply.started": "2025-05-19T04:56:07.354729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1002, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>svg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Golden wheat fields under a setting sun',</td>\n",
       "      <td>&lt;svg viewBox=\"0 0 200 200\" width=\"200\" height=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Snowy mountains under a clear blue sky',</td>\n",
       "      <td>&lt;svg viewBox=\"0 0 200 100\" width=\"200\" height=...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  description  \\\n",
       "0  'Golden wheat fields under a setting sun',   \n",
       "1   'Snowy mountains under a clear blue sky',   \n",
       "\n",
       "                                                 svg  \n",
       "0  <svg viewBox=\"0 0 200 200\" width=\"200\" height=...  \n",
       "1  <svg viewBox=\"0 0 200 100\" width=\"200\" height=...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path= kagglehub.dataset_download('vinothkumarsekar89/svg-generation-sample-training-data')\n",
    "df_train = pd.read_csv('/kaggle/input/svg-generation-sample-training-data/train_data_svg_generation_sample.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:56:07.584788Z",
     "iopub.status.busy": "2025-05-19T04:56:07.584523Z",
     "iopub.status.idle": "2025-05-19T04:56:07.592181Z",
     "shell.execute_reply": "2025-05-19T04:56:07.591485Z",
     "shell.execute_reply.started": "2025-05-19T04:56:07.584765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Golden wheat fields under a setting sun',\n",
      " 'Snowy mountains under a clear blue sky',\n",
      " 'Checkerboard pattern with alternating green and black squares',\n",
      " 'Crimson and gold spirals intertwining',\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(df_train['description'].loc[0])\n",
    "print(df_train['description'].loc[1])\n",
    "print(df_train['description'].loc[2])\n",
    "print(df_train['description'].loc[3])\n",
    "print(type(df_train['description'].loc[3]))\n",
    "\n",
    "des_list = list()\n",
    "\n",
    "for i in range(10,20):\n",
    "    des_list.append(df_train['description'].loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:56:07.593096Z",
     "iopub.status.busy": "2025-05-19T04:56:07.592916Z",
     "iopub.status.idle": "2025-05-19T04:56:54.371910Z",
     "shell.execute_reply": "2025-05-19T04:56:54.371224Z",
     "shell.execute_reply.started": "2025-05-19T04:56:07.593082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  'Golden wheat fields under a setting sun',\n",
      "thinking content: \n",
      " <think>\n",
      "Okay, the user wants me to generate SVG code for the description \"Golden wheat fields under a setting sun\". Let me start by breaking down the elements mentioned here.\n",
      "\n",
      "First, the main subjects are wheat fields and a setting sun. The color golden suggests warm tones, maybe yellows and oranges. The setting sun implies a sunset, so I should think about the colors of the sky during that time‚Äîperhaps pink, orange, and purple hues.\n",
      "\n",
      "I need to create a landscape. In SVG, I can use rectangles for the sky and the fields. The wheat fields could be represented with a gradient from golden yellow to a lighter shade. The sun might be a circle with a gradient to simulate the setting sun effect.\n",
      "\n",
      "I should consider the layers. The sky at the top, then the wheat fields in the middle, and maybe some clouds to add realism. The sun would be positioned in the upper right corner to indicate it's setting.\n",
      "\n",
      "Gradients are essential here. For the sky, a gradient from deep blue to pink. For the wheat fields, a gradient from golden yellow to a lighter yellow. The sun could have a gradient from orange to red.\n",
      "\n",
      "I need to make sure the SVG is properly structured with defs for gradients, then the shapes. The sky rectangle, then the wheat fields with a linear gradient, and the sun as a circle with another gradient.\n",
      "\n",
      "Also, the user specified no comments or extra messages, just the code. So I have to be concise. Check the character count to ensure it's under 200 characters, but the SVG code itself will be longer. Wait, the description is under 200 characters, but the SVG code is separate. The user's instruction says the description is around 50 characters on average, which this one is. So the code generation is okay.\n",
      "\n",
      "Make sure the SVG is valid. Use xmlns, define gradients, and proper elements. Maybe add some clouds using simple shapes or paths, but maybe the user wants it simple. Since the description is generic, maybe just the sky, fields, and sun without clouds. Let me go with that.\n",
      "\n",
      "So, the SVG will have a gradient for the sky, a gradient for the wheat, and a sun. Position the sun in the upper right. The wheat fields could be a rectangle in the middle with the gradient. Let me draft the code.\n",
      "</think>\n",
      "content: \n",
      " <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"500\" height=\"300\"><defs><linearGradient id=\"sky\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\"><stop offset=\"0%\" stop-color=\"#87CEEB\"/><stop offset=\"100%\" stop-color=\"#FF69B4\"/></linearGradient><linearGradient id=\"wheat\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\"><stop offset=\"0%\" stop-color=\"#FFD700\"/><stop offset=\"100%\" stop-color=\"#FFFACD\"/></linearGradient><linearGradient id=\"sun\" x1=\"0\" y1=\"0\" x2=\"1\" y2=\"1\"><stop offset=\"0%\" stop-color=\"#FFA500\"/><stop offset=\"100%\" stop-color=\"#FF4500\"/></linearGradient></defs><rect width=\"100%\" height=\"100%\" fill=\"#87CEEB\"/><rect y=\"100\" width=\"100%\" height=\"150\" fill=\"url(#wheat)\"/><circle cx=\"450\" cy=\"150\" r=\"40\" fill=\"url(#sun)\" /></svg>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"500\" height=\"300\"><defs><linearGradient id=\"sky\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\"><stop offset=\"0%\" stop-color=\"#87CEEB\"/><stop offset=\"100%\" stop-color=\"#FF69B4\"/></linearGradient><linearGradient id=\"wheat\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\"><stop offset=\"0%\" stop-color=\"#FFD700\"/><stop offset=\"100%\" stop-color=\"#FFFACD\"/></linearGradient><linearGradient id=\"sun\" x1=\"0\" y1=\"0\" x2=\"1\" y2=\"1\"><stop offset=\"0%\" stop-color=\"#FFA500\"/><stop offset=\"100%\" stop-color=\"#FF4500\"/></linearGradient></defs><rect width=\"100%\" height=\"100%\" fill=\"#87CEEB\"/><rect y=\"100\" width=\"100%\" height=\"150\" fill=\"url(#wheat)\"/><circle cx=\"450\" cy=\"150\" r=\"40\" fill=\"url(#sun)\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"'Golden wheat fields under a setting sun',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\" width=\"200\" height=\"200\">\n",
       "  <!-- Background for the sky -->\n",
       "  <rect x=\"0\" y=\"0\" width=\"200\" height=\"100\" fill=\"orange\" opacity=\"0.7\"/>\n",
       "  \n",
       "  <!-- Sun -->\n",
       "  <circle cx=\"100\" cy=\"50\" r=\"30\" fill=\"yellow\" opacity=\"0.8\"/>\n",
       "  \n",
       "  <!-- Wheat fields -->\n",
       "  <rect x=\"0\" y=\"100\" width=\"200\" height=\"100\" fill=\"goldenrod\"/>\n",
       "  \n",
       "  <!-- Wheat stalks -->\n",
       "  <g stroke=\"saddlebrown\" stroke-width=\"2\">\n",
       "    <line x1=\"30\" y1=\"100\" x2=\"30\" y2=\"150\"/>\n",
       "    <line x1=\"50\" y1=\"100\" x2=\"50\" y2=\"150\"/>\n",
       "    <line x1=\"70\" y1=\"100\" x2=\"70\" y2=\"150\"/>\n",
       "    <line x1=\"90\" y1=\"100\" x2=\"90\" y2=\"150\"/>\n",
       "    <line x1=\"110\" y1=\"100\" x2=\"110\" y2=\"150\"/>\n",
       "    <line x1=\"130\" y1=\"100\" x2=\"130\" y2=\"150\"/>\n",
       "    <line x1=\"150\" y1=\"100\" x2=\"150\" y2=\"150\"/>\n",
       "    <line x1=\"170\" y1=\"100\" x2=\"170\" y2=\"150\"/>\n",
       "  </g>\n",
       "  \n",
       "  <!-- Wheat heads -->\n",
       "  <g fill=\"gold\" stroke=\"saddlebrown\" stroke-width=\"0.5\">\n",
       "    <ellipse cx=\"30\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "    <ellipse cx=\"50\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "    <ellipse cx=\"70\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "    <ellipse cx=\"90\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "    <ellipse cx=\"110\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "    <ellipse cx=\"130\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "    <ellipse cx=\"150\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "    <ellipse cx=\"170\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
       "  </g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"'Golden wheat fields under a setting sun',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 44.5 s, sys: 510 ms, total: 45 s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "def show_svg(svg_code: str, text: str = \"\"):\n",
    "    display(SVG(svg_code))\n",
    "    if text:\n",
    "        display(text)\n",
    "        \n",
    "sys_prompt = \"\"\"You are a SVG Image code generator and you only generate code without comments  and other messages, nothing else.\n",
    "\n",
    "The descriptions are of common, generic subjects. No brand name or trademark or personal name occurs in any description. No people, even in generic form, occur in any description.\n",
    "The subjects described span about a dozen categories. Three of these categories, landscapes, abstract, and fashion.\n",
    "No description has more than 200 characters. The average length is around 50 characters.\n",
    "\n",
    "Generate the code for provided description.\"\"\"\n",
    "\n",
    "def gen(idx, thinking_mode=False):\n",
    "\n",
    "    prompt, original_svg_code = str(df_train['description'].loc[idx]),str(df_train['svg'].loc[idx])\n",
    "    # prompt = str(prompt)\n",
    "    # prepare the model input\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=thinking_mode # Switches between thinking and non-thinking modes. Default is True.\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # conduct text completion\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=32768\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "    \n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 ()\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "    \n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "    \n",
    "    # print(\"thinking content:\", thinking_content)\n",
    "    print(\"Prompt: \",prompt)\n",
    "    print(\"thinking content: \\n\",thinking_content)\n",
    "    print(\"content: \\n\",content);print();print()\n",
    "    \n",
    "    show_svg(content,prompt); print()\n",
    "    # show_svg(thinking_content, prompt);print()\n",
    "    show_svg(original_svg_code, prompt); print()\n",
    "    \n",
    "    return content\n",
    "\n",
    "r0 = gen(0,True)\n",
    "\n",
    "# 8.2 s -> Not thinking\n",
    "# 1min 11s -> With thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:56:54.374483Z",
     "iopub.status.busy": "2025-05-19T04:56:54.374220Z",
     "iopub.status.idle": "2025-05-19T04:57:11.058413Z",
     "shell.execute_reply": "2025-05-19T04:57:11.057854Z",
     "shell.execute_reply.started": "2025-05-19T04:56:54.374468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:   'Snowy mountains under a clear blue sky',\n",
      "thinking content: \n",
      " \n",
      "content: \n",
      " <svg width=\"200\" height=\"200\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "  <rect width=\"200\" height=\"200\" fill=\"skyblue\"/>\n",
      "  <polygon points=\"50,150 150,150 100,50\" fill=\"white\"/>\n",
      "  <circle cx=\"100\" cy=\"100\" r=\"30\" fill=\"snow\"/>\n",
      "</svg>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"200\" height=\"200\" viewBox=\"0 0 200 200\">\n",
       "  <rect width=\"200\" height=\"200\" fill=\"skyblue\"/>\n",
       "  <polygon points=\"50,150 150,150 100,50\" fill=\"white\"/>\n",
       "  <circle cx=\"100\" cy=\"100\" r=\"30\" fill=\"snow\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" 'Snowy mountains under a clear blue sky',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 100\" width=\"200\" height=\"100\">\n",
       "  <!-- Sky -->\n",
       "  <rect x=\"0\" y=\"0\" width=\"200\" height=\"100\" fill=\"skyblue\"/>\n",
       "  \n",
       "  <!-- Mountains -->\n",
       "  <polygon points=\"30,80 70,30 110,80\" fill=\"white\" stroke=\"gray\" stroke-width=\"1\"/>\n",
       "  <polygon points=\"90,80 130,40 170,80\" fill=\"white\" stroke=\"gray\" stroke-width=\"1\"/>\n",
       "  \n",
       "  <!-- Ground -->\n",
       "  <rect x=\"0\" y=\"80\" width=\"200\" height=\"20\" fill=\"lightgray\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" 'Snowy mountains under a clear blue sky',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:   'Checkerboard pattern with alternating green and black squares',\n",
      "thinking content: \n",
      " \n",
      "content: \n",
      " <svg width=\"200\" height=\"200\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "  <rect width=\"100%\" height=\"100%\" fill=\"black\" />\n",
      "  <rect width=\"100%\" height=\"100%\" fill=\"green\" />\n",
      "  <pattern id=\"checker\" width=\"20\" height=\"20\" patternUnits=\"userSpaceOnUse\">\n",
      "    <rect width=\"10\" height=\"10\" fill=\"black\" />\n",
      "    <rect x=\"10\" y=\"10\" width=\"10\" height=\"10\" fill=\"green\" />\n",
      "  </pattern>\n",
      "  <rect width=\"100%\" height=\"100%\" fill=\"url(#checker)\" />\n",
      "</svg>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"200\" height=\"200\">\n",
       "  <rect width=\"100%\" height=\"100%\" fill=\"black\"/>\n",
       "  <rect width=\"100%\" height=\"100%\" fill=\"green\"/>\n",
       "  <pattern id=\"checker\" width=\"20\" height=\"20\" patternUnits=\"userSpaceOnUse\">\n",
       "    <rect width=\"10\" height=\"10\" fill=\"black\"/>\n",
       "    <rect x=\"10\" y=\"10\" width=\"10\" height=\"10\" fill=\"green\"/>\n",
       "  </pattern>\n",
       "  <rect width=\"100%\" height=\"100%\" fill=\"url(#checker)\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" 'Checkerboard pattern with alternating green and black squares',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg viewBox=\"0 0 100 100\" width=\"100\" height=\"100\">\n",
       "  <rect x=\"0\" y=\"0\" width=\"50\" height=\"50\" fill=\"green\"/>\n",
       "  <rect x=\"50\" y=\"0\" width=\"50\" height=\"50\" fill=\"black\"/>\n",
       "  <rect x=\"0\" y=\"50\" width=\"50\" height=\"50\" fill=\"black\"/>\n",
       "  <rect x=\"50\" y=\"50\" width=\"50\" height=\"50\" fill=\"green\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" 'Checkerboard pattern with alternating green and black squares',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r1 = gen(1)\n",
    "r2 = gen(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:57:11.059308Z",
     "iopub.status.busy": "2025-05-19T04:57:11.059076Z",
     "iopub.status.idle": "2025-05-19T04:57:19.040852Z",
     "shell.execute_reply": "2025-05-19T04:57:19.040160Z",
     "shell.execute_reply.started": "2025-05-19T04:57:11.059294Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:   'Crimson and gold spirals intertwining',\n",
      "thinking content: \n",
      " \n",
      "content: \n",
      " <svg width=\"200\" height=\"200\" viewBox=\"0 0 200 200\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "  <g fill=\"crimson\" stroke=\"gold\" stroke-width=\"2\">\n",
      "    <path d=\"M100,50 A100,100 0 1,1 150,150\" />\n",
      "    <path d=\"M150,150 A100,100 0 1,1 100,50\" />\n",
      "  </g>\n",
      "</svg>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"200\" height=\"200\" viewBox=\"0 0 200 200\">\n",
       "  <g fill=\"crimson\" stroke=\"gold\" stroke-width=\"2\">\n",
       "    <path d=\"M100,50 A100,100 0 1,1 150,150\"/>\n",
       "    <path d=\"M150,150 A100,100 0 1,1 100,50\"/>\n",
       "  </g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" 'Crimson and gold spirals intertwining',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\" width=\"200\" height=\"200\">\n",
       "  <defs>\n",
       "    <linearGradient id=\"crimsonGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
       "      <stop offset=\"0%\" style=\"stop-color:crimson;stop-opacity:1\"/>\n",
       "      <stop offset=\"100%\" style=\"stop-color:gold;stop-opacity:1\"/>\n",
       "    </linearGradient>\n",
       "  </defs>\n",
       "  <g transform=\"translate(100,100)\">\n",
       "    <path d=\"M0,0 C20,-20 40,-20 60,0 S100,20 120,0\" fill=\"none\" stroke=\"url(#crimsonGradient)\" stroke-width=\"4\" transform=\"rotate(0)\"/>\n",
       "    <path d=\"M0,0 C20,-20 40,-20 60,0 S100,20 120,0\" fill=\"none\" stroke=\"url(#crimsonGradient)\" stroke-width=\"4\" transform=\"rotate(60)\"/>\n",
       "    <path d=\"M0,0 C20,-20 40,-20 60,0 S100,20 120,0\" fill=\"none\" stroke=\"url(#crimsonGradient)\" stroke-width=\"4\" transform=\"rotate(120)\"/>\n",
       "    <path d=\"M0,0 C20,-20 40,-20 60,0 S100,20 120,0\" fill=\"none\" stroke=\"url(#crimsonGradient)\" stroke-width=\"4\" transform=\"rotate(180)\"/>\n",
       "    <path d=\"M0,0 C20,-20 40,-20 60,0 S100,20 120,0\" fill=\"none\" stroke=\"url(#crimsonGradient)\" stroke-width=\"4\" transform=\"rotate(240)\"/>\n",
       "    <path d=\"M0,0 C20,-20 40,-20 60,0 S100,20 120,0\" fill=\"none\" stroke=\"url(#crimsonGradient)\" stroke-width=\"4\" transform=\"rotate(300)\"/>\n",
       "  </g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" 'Crimson and gold spirals intertwining',\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r3 = gen(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:57:19.042013Z",
     "iopub.status.busy": "2025-05-19T04:57:19.041714Z",
     "iopub.status.idle": "2025-05-19T04:57:19.047625Z",
     "shell.execute_reply": "2025-05-19T04:57:19.046841Z",
     "shell.execute_reply.started": "2025-05-19T04:57:19.041997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(des_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data into dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:57:19.048683Z",
     "iopub.status.busy": "2025-05-19T04:57:19.048424Z",
     "iopub.status.idle": "2025-05-19T04:57:19.149329Z",
     "shell.execute_reply": "2025-05-19T04:57:19.148487Z",
     "shell.execute_reply.started": "2025-05-19T04:57:19.048661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93db79b26a3e498ebf7673d77ed9f9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    topics = examples[\"description\"]  # Using 'topic' as instruction\n",
    "    svgs = examples[\"svg\"]  # Using 'svg_code' as output\n",
    "    texts = []\n",
    "\n",
    "    \n",
    "    for topic, svg_code in zip(topics, svgs):\n",
    "        # No additional input is needed, so we pass an empty string\n",
    "        text = alpaca_prompt.format(f\"Generate a SVG code for the given input:\",topic,svg_code) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "       \n",
    "    return { \"text\": texts }\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_train = dataset_train.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "#dataset_test = Dataset.from_pandas(df_test)\n",
    "#dataset_test = dataset_test.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:57:19.150375Z",
     "iopub.status.busy": "2025-05-19T04:57:19.150123Z",
     "iopub.status.idle": "2025-05-19T04:57:19.155143Z",
     "shell.execute_reply": "2025-05-19T04:57:19.154408Z",
     "shell.execute_reply.started": "2025-05-19T04:57:19.150355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(EOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:57:19.156124Z",
     "iopub.status.busy": "2025-05-19T04:57:19.155872Z",
     "iopub.status.idle": "2025-05-19T04:57:19.170510Z",
     "shell.execute_reply": "2025-05-19T04:57:19.169839Z",
     "shell.execute_reply.started": "2025-05-19T04:57:19.156091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['description', 'svg', 'text'],\n",
       "    num_rows: 1002\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:57:19.171492Z",
     "iopub.status.busy": "2025-05-19T04:57:19.171215Z",
     "iopub.status.idle": "2025-05-19T04:57:19.189788Z",
     "shell.execute_reply": "2025-05-19T04:57:19.189156Z",
     "shell.execute_reply.started": "2025-05-19T04:57:19.171473Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Golden wheat fields under a setting sun',\n",
      "<svg viewBox=\"0 0 200 200\" width=\"200\" height=\"200\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "  <!-- Background for the sky -->\n",
      "  <rect x=\"0\" y=\"0\" width=\"200\" height=\"100\" fill=\"orange\" opacity=\"0.7\"/>\n",
      "  \n",
      "  <!-- Sun -->\n",
      "  <circle cx=\"100\" cy=\"50\" r=\"30\" fill=\"yellow\" opacity=\"0.8\"/>\n",
      "  \n",
      "  <!-- Wheat fields -->\n",
      "  <rect x=\"0\" y=\"100\" width=\"200\" height=\"100\" fill=\"goldenrod\"/>\n",
      "  \n",
      "  <!-- Wheat stalks -->\n",
      "  <g stroke=\"saddlebrown\" stroke-width=\"2\">\n",
      "    <line x1=\"30\" y1=\"100\" x2=\"30\" y2=\"150\"/>\n",
      "    <line x1=\"50\" y1=\"100\" x2=\"50\" y2=\"150\"/>\n",
      "    <line x1=\"70\" y1=\"100\" x2=\"70\" y2=\"150\"/>\n",
      "    <line x1=\"90\" y1=\"100\" x2=\"90\" y2=\"150\"/>\n",
      "    <line x1=\"110\" y1=\"100\" x2=\"110\" y2=\"150\"/>\n",
      "    <line x1=\"130\" y1=\"100\" x2=\"130\" y2=\"150\"/>\n",
      "    <line x1=\"150\" y1=\"100\" x2=\"150\" y2=\"150\"/>\n",
      "    <line x1=\"170\" y1=\"100\" x2=\"170\" y2=\"150\"/>\n",
      "  </g>\n",
      "  \n",
      "  <!-- Wheat heads -->\n",
      "  <g fill=\"gold\" stroke=\"saddlebrown\" stroke-width=\"0.5\">\n",
      "    <ellipse cx=\"30\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "    <ellipse cx=\"50\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "    <ellipse cx=\"70\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "    <ellipse cx=\"90\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "    <ellipse cx=\"110\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "    <ellipse cx=\"130\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "    <ellipse cx=\"150\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "    <ellipse cx=\"170\" cy=\"95\" rx=\"5\" ry=\"10\"/>\n",
      "  </g>\n",
      "</svg>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train['description'][0])\n",
    "print(dataset_train['svg'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:57:19.190968Z",
     "iopub.status.busy": "2025-05-19T04:57:19.190676Z",
     "iopub.status.idle": "2025-05-19T04:57:19.206097Z",
     "shell.execute_reply": "2025-05-19T04:57:19.205312Z",
     "shell.execute_reply.started": "2025-05-19T04:57:19.190942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a SVG code for the given input:\\n\\n### Input:\\n\\'Golden wheat fields under a setting sun\\',\\n\\n### Response:\\n<svg viewBox=\"0 0 200 200\" width=\"200\" height=\"200\" xmlns=\"http://www.w3.org/2000/svg\">\\n  <!-- Background for the sky -->\\n  <rect x=\"0\" y=\"0\" width=\"200\" height=\"100\" fill=\"orange\" opacity=\"0.7\"/>\\n  \\n  <!-- Sun -->\\n  <circle cx=\"100\" cy=\"50\" r=\"30\" fill=\"yellow\" opacity=\"0.8\"/>\\n  \\n  <!-- Wheat fields -->\\n  <rect x=\"0\" y=\"100\" width=\"200\" height=\"100\" fill=\"goldenrod\"/>\\n  \\n  <!-- Wheat stalks -->\\n  <g stroke=\"saddlebrown\" stroke-width=\"2\">\\n    <line x1=\"30\" y1=\"100\" x2=\"30\" y2=\"150\"/>\\n    <line x1=\"50\" y1=\"100\" x2=\"50\" y2=\"150\"/>\\n    <line x1=\"70\" y1=\"100\" x2=\"70\" y2=\"150\"/>\\n    <line x1=\"90\" y1=\"100\" x2=\"90\" y2=\"150\"/>\\n    <line x1=\"110\" y1=\"100\" x2=\"110\" y2=\"150\"/>\\n    <line x1=\"130\" y1=\"100\" x2=\"130\" y2=\"150\"/>\\n    <line x1=\"150\" y1=\"100\" x2=\"150\" y2=\"150\"/>\\n    <line x1=\"170\" y1=\"100\" x2=\"170\" y2=\"150\"/>\\n  </g>\\n  \\n  <!-- Wheat heads -->\\n  <g fill=\"gold\" stroke=\"saddlebrown\" stroke-width=\"0.5\">\\n    <ellipse cx=\"30\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n    <ellipse cx=\"50\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n    <ellipse cx=\"70\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n    <ellipse cx=\"90\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n    <ellipse cx=\"110\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n    <ellipse cx=\"130\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n    <ellipse cx=\"150\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n    <ellipse cx=\"170\" cy=\"95\" rx=\"5\" ry=\"10\"/>\\n  </g>\\n</svg>\\n<|im_end|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset sample output\n",
    "dataset_train['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFT trainer Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T05:04:51.134648Z",
     "iopub.status.busy": "2025-05-19T05:04:51.134060Z",
     "iopub.status.idle": "2025-05-19T05:04:53.359299Z",
     "shell.execute_reply": "2025-05-19T05:04:53.358474Z",
     "shell.execute_reply.started": "2025-05-19T05:04:51.134622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b03792bd6e449ea200a7acc4381796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/1002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset_train,\n",
    "    #eval_dataset = dataset_test,  # Add test dataset here\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 3, \n",
    "        max_steps = max_iter_steps,\n",
    "        learning_rate = 5e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\", # \"adamw_torch\" better for fp16\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 123,\n",
    "        #eval_strategy = \"steps\", \n",
    "        #eval_steps = 100, \n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n",
    "\n",
    "#  Unsloth:‚ÄáTokenizing‚Äá[\"text\"]‚Äá(num_proc=2):‚Äá100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T05:05:10.411002Z",
     "iopub.status.busy": "2025-05-19T05:05:10.410370Z",
     "iopub.status.idle": "2025-05-19T07:03:53.052544Z",
     "shell.execute_reply": "2025-05-19T07:03:53.051910Z",
     "shell.execute_reply.started": "2025-05-19T05:05:10.410975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,002 | Num Epochs = 5 | Total steps = 300\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 264,241,152/4,286,709,248 (6.16% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 1:58:11, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.260200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.180800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.080200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.077500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.049800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 19min 34s, sys: 39min 6s, total: 1h 58min 40s\n",
      "Wall time: 1h 58min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.13005348453919094, metrics={'train_runtime': 7120.5285, 'train_samples_per_second': 0.674, 'train_steps_per_second': 0.042, 'total_flos': 9.811926103711334e+16, 'train_loss': 0.13005348453919094})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()\n",
    "# Wall time: 1h 58min 42s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge LoRA and save the full model in FP16 format (vLLM-compatible) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:09:12.188511Z",
     "iopub.status.busy": "2025-05-19T07:09:12.187883Z",
     "iopub.status.idle": "2025-05-19T07:10:17.284362Z",
     "shell.execute_reply": "2025-05-19T07:10:17.283798Z",
     "shell.execute_reply.started": "2025-05-19T07:09:12.188488Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\n",
      "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
      "To force `safe_serialization`, set it to `None` instead.\n",
      "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
      "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 16.99 out of 31.35 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 8/36 [00:00<00:01, 23.66it/s]\n",
      "We will save to Disk and not RAM now.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:12<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00001-of-00002.bin...\n",
      "Unsloth: Saving Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00002-of-00002.bin...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#save merged 16bit\n",
    "import os\n",
    "dir_path = \"Qwen3-4B-LoRA-SVG-Generation\"\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "model.save_pretrained_merged(dir_path, tokenizer, save_method = \"merged_16bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the model to kagglehub(use your own model handle under your username.!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:11:10.357545Z",
     "iopub.status.busy": "2025-05-19T07:11:10.356949Z",
     "iopub.status.idle": "2025-05-19T07:11:10.372133Z",
     "shell.execute_reply": "2025-05-19T07:11:10.371315Z",
     "shell.execute_reply.started": "2025-05-19T07:11:10.357524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d01fe621e264c55a4030acd7fef8668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # You may need this login if you want to upload model to kagglehub from local machine.\n",
    "# kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:19:40.456398Z",
     "iopub.status.busy": "2025-05-19T07:19:40.456103Z",
     "iopub.status.idle": "2025-05-19T07:19:40.462748Z",
     "shell.execute_reply": "2025-05-19T07:19:40.462149Z",
     "shell.execute_reply.started": "2025-05-19T07:19:40.456380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/outputs/checkpoint-300/rng_state.pth\n",
      "/kaggle/working/outputs/checkpoint-300/adapter_model.safetensors\n",
      "/kaggle/working/outputs/checkpoint-300/trainer_state.json\n",
      "/kaggle/working/outputs/checkpoint-300/README.md\n",
      "/kaggle/working/outputs/checkpoint-300/tokenizer.json\n",
      "/kaggle/working/outputs/checkpoint-300/tokenizer_config.json\n",
      "/kaggle/working/outputs/checkpoint-300/scheduler.pt\n",
      "/kaggle/working/outputs/checkpoint-300/merges.txt\n",
      "/kaggle/working/outputs/checkpoint-300/optimizer.pt\n",
      "/kaggle/working/outputs/checkpoint-300/adapter_config.json\n",
      "/kaggle/working/outputs/checkpoint-300/scaler.pt\n",
      "/kaggle/working/outputs/checkpoint-300/training_args.bin\n",
      "/kaggle/working/outputs/checkpoint-300/added_tokens.json\n",
      "/kaggle/working/outputs/checkpoint-300/vocab.json\n",
      "/kaggle/working/outputs/checkpoint-300/special_tokens_map.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/config.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00001-of-00002.bin\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/tokenizer.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/tokenizer_config.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/merges.txt\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00002-of-00002.bin\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model.bin.index.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/added_tokens.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/vocab.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/special_tokens_map.json\n",
      "/kaggle/working/Qwen3-4B-LoRA-SVG-Generation/generation_config.json\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothKTOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothXPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothAlignPropTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothPRMTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothPPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothDPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothCPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothBCOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothRLOOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothOnlineDPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothORPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothDDPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothGRPOTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothGKDTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothRewardTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/UnslothNashMDTrainer.py\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothGKDTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothCPOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothPRMTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothKTOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothOnlineDPOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothBCOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothRewardTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothXPOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothGRPOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothAlignPropTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothNashMDTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothRLOOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothDPOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothORPOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothDDPOTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothSFTTrainer.cpython-311.pyc\n",
      "/kaggle/working/unsloth_compiled_cache/__pycache__/UnslothPPOTrainer.cpython-311.pyc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:22:10.252837Z",
     "iopub.status.busy": "2025-05-19T07:22:10.252226Z",
     "iopub.status.idle": "2025-05-19T07:23:24.028231Z",
     "shell.execute_reply": "2025-05-19T07:23:24.027349Z",
     "shell.execute_reply.started": "2025-05-19T07:22:10.252814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Model https://www.kaggle.com/models/hritwijkamble/qwen3_4b_svg_code_generation/transformers/01 ...\n",
      "Model 'qwen3_4b_svg_code_generation' does not exist or access is forbidden for user 'hritwijkamble'. Creating or handling Model...\n",
      "Model 'qwen3_4b_svg_code_generation' Created.\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [00:00<00:00, 1.32kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/config.json (785B)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00001-of-00002.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.97G/4.97G [00:34<00:00, 143MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00001-of-00002.bin (5GB)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.4M/11.4M [00:00<00:00, 22.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/tokenizer.json (11MB)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.73k/9.73k [00:00<00:00, 25.4kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/tokenizer_config.json (10KB)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/merges.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.67M/1.67M [00:00<00:00, 4.62MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/merges.txt (2MB)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00002-of-00002.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.08G/3.08G [00:23<00:00, 132MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model-00002-of-00002.bin (3GB)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model.bin.index.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32.8k/32.8k [00:00<00:00, 95.7kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/pytorch_model.bin.index.json (32KB)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/added_tokens.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 707/707 [00:00<00:00, 1.36kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/added_tokens.json (707B)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/vocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.78M/2.78M [00:00<00:00, 4.88MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/vocab.json (3MB)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 613/613 [00:00<00:00, 1.74kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/special_tokens_map.json (613B)\n",
      "Starting upload for file /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:00<00:00, 661B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: /kaggle/working/Qwen3-4B-LoRA-SVG-Generation/generation_config.json (237B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model instance has been created.\n",
      "Files are being processed...\n",
      "See at: https://www.kaggle.com/models/hritwijkamble/qwen3_4b_svg_code_generation/transformers/01\n"
     ]
    }
   ],
   "source": [
    "# Replace with path to directory containing model files.\n",
    "LOCAL_MODEL_DIR = \"/kaggle/working/Qwen3-4B-LoRA-SVG-Generation\"\n",
    "\n",
    "MODEL_SLUG = 'qwen3_4b_svg_code_generation' # Replace with model slug.\n",
    "\n",
    "# Learn more about naming model variations at\n",
    "# https://www.kaggle.com/docs/models#name-model.\n",
    "VARIATION_SLUG = '01' # Replace with variation slug.\n",
    "\n",
    "kagglehub.model_upload(\n",
    "  handle = f\"hritwijkamble/{MODEL_SLUG}/transformers/{VARIATION_SLUG}\",\n",
    "  local_model_dir = LOCAL_MODEL_DIR,\n",
    "  version_notes = 'Update 2025-05-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:23:56.123282Z",
     "iopub.status.busy": "2025-05-19T07:23:56.122971Z",
     "iopub.status.idle": "2025-05-19T07:23:56.127447Z",
     "shell.execute_reply": "2025-05-19T07:23:56.126851Z",
     "shell.execute_reply.started": "2025-05-19T07:23:56.123262Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.!\n"
     ]
    }
   ],
   "source": [
    "print('Done.!')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11735795,
     "sourceId": 89659,
     "sourceType": "competition"
    },
    {
     "datasetId": 7317232,
     "sourceId": 11659965,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 322000,
     "modelInstanceId": 301514,
     "sourceId": 363134,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
